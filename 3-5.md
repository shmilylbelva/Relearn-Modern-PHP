MySQL主从复制(Master-Slave)与读写分离(MySQL-Proxy)实践
Mysql作为目前世界上使用最广泛的免费数据库，相信所有从事系统运维的工程师都一定接触过。但在实际的生产环境中，由单台Mysql作为独立的数据库是完全不能满足实际需求的，无论是在安全性，高可用性以及高并发等各个方面。
因此，一般来说都是通过 主从复制（Master-Slave）的方式来同步数据，再通过读写分离（MySQL-Proxy）来提升数据库的并发负载能力 这样的方案来进行部署与实施的。
如下图所示：

![image.png](http://upload-images.jianshu.io/upload_images/2825702-da877fda3f67b06c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
下面是我在实际工作过程中所整理的笔记，在此分享出来，以供大家参考。
**一、MySQL的安装与配置**
具体的安装过程，建议参考我的这一篇文章：[http://heylinux.com/archives/993.html](http://heylinux.com/archives/993.html) 值得一提的是，我的安装过程都是源码包编译安装的，并且所有的配置与数据等都统一规划到了/opt/mysql目录中，因此在一台服务器上安装完成以后，可以将整个mysql目录打包，然后传到其它服务器上解包，便可立即使用。**二、MySQL主从复制**
场景描述： 主数据库服务器：192.168.10.130，MySQL已经安装，并且无应用数据。 从数据库服务器：192.168.10.131，MySQL已经安装，并且无应用数据。**2.1 主服务器上进行的操作**
启动mysql服务
```
/opt/mysql/init.d/mysql start
```
通过命令行登录管理MySQL服务器
```
/opt/mysql/bin/mysql -uroot -p'new-password'
```
授权给从数据库服务器192.168.10.131
```
mysql> GRANT REPLICATION SLAVE ON *.* to 'rep1'@'192.168.10.131' identified by ‘password’;
```
查询主数据库状态
```
Mysql> show master status; 
```
| File | Position | Binlog_Do_DB |Binlog_Ignore_DB |
| ------------- |:-------------:| -----:|-----:|
| mysql-bin.000005     | right-aligned | $1600 |
| col 2 is      | 261 |    ||

记录下 FILE 及 Position 的值，在后面进行从服务器操作的时候需要用到。
**2.2 配置从服务器**
修改从服务器的配置文件/opt/mysql/etc/my.cnf 将 server-id = 1修改为 server-id = 10，并确保这个ID没有被别的MySQL服务所使用。启动mysql服务
```
/opt/mysql/init.d/mysql start
```
通过命令行登录管理MySQL服务器
```
/opt/mysql/bin/mysql -uroot -p'new-password'
```
执行同步SQL语句
```
mysql> change master to master_host=’192.168.10.130’, master_user=’rep1’, master_password=’password’, master_log_file=’mysql-bin.000005’, master_log_pos=261;
```
正确执行后启动Slave同步进程
```
mysql> start slave;
```
主从同步检查
```
mysql> show slave status\G 
==============================================
 **************** 1. row ******************* 
Slave_IO_State: Master_Host: 192.168.10.130 
Master_User: rep1
 Master_Port: 3306
 Connect_Retry: 60 
Master_Log_File: mysql-bin.000005 
Read_Master_Log_Pos: 415 
Relay_Log_File: localhost-relay-bin.000008 
Relay_Log_Pos: 561 
Relay_Master_Log_File: mysql-bin.000005 
Slave_IO_Running: YES 
Slave_SQL_Running: YES 
Replicate_Do_DB: ……………省略若干…………… 
Master_Server_Id: 1 
1 row in set (0.01 sec) 
==============================================
```
其中Slave_IO_Running 与 Slave_SQL_Running 的值都必须为YES，才表明状态正常。
**如果主服务器已经存在应用数据，则在进行主从复制时，需要做以下处理：**
(1)主数据库进行锁表操作，不让数据再进行写入动作
```
mysql> FLUSH TABLES WITH READ LOCK;
```
(2)查看主数据库状态
```
mysql> show master status;
```
(3)记录下 FILE 及 Position 的值。
将主服务器的数据文件（整个/opt/mysql/data目录）复制到从服务器，建议通过tar归档压缩后再传到从服务器解压。
(4)取消主数据库锁定
```
mysql> UNLOCK TABLES;
```
**2.3 验证主从复制效果**
**主服务器上的操作**
在主服务器上创建数据库first_db
```
mysql> create database first_db; 
Query Ok, 1 row affected (0.01 sec)
```
在主服务器上创建表first_tb
```
mysql> create table first_tb(id int(3),name char(10)); 
Query Ok, 1 row affected (0.00 sec)
```
在主服务器上的表first_tb中插入记录
```
mysql> insert into first_tb values (001,’myself’); 
Query Ok, 1 row affected (0.00 sec)
```
**在从服务器上查看**
```
mysql> show databases;
```
=============================
+--------------------+ | Database |
+--------------------+ | information_schema | | first_db | | mysql | | performance_schema | | test |
+--------------------+ 5 rows in set (0.01 sec)
=============================
数据库first_db已经自动生成
```
mysql> use first_db
Database chagedmysql> show tables;
```
=============================
+--------------------+ | Tables_in_first_db |
+--------------------+ | first_tb |
+--------------------+
1 row in set (0.02 sec)
=============================
数据库表first_tb也已经自动创建
```
mysql> select * from first_tb;
```
=============================
+------+------+ | id | name |
+------+------+ | 1 | myself |
+------+------+ 1 rows in set (0.00 sec)
=============================
记录也已经存在由此，整个MySQL主从复制的过程就完成了，接下来，我们进行MySQL读写分离的安装与配置。

**三、MySQL读写分离**
场景描述：
数据库Master主服务器：192.168.10.130
数据库Slave从服务器：192.168.10.131
MySQL-Proxy调度服务器：192.168.10.132
给调度服务器分配账户密码：分别在主从库上
```
mysql>
grant all on *.* to shmily@'192.168.1.%' identified by 'shmily';
```
以下操作，均是在192.168.10.132即MySQL-Proxy调度服务器 上进行的。
1 安装java环境  我用的是 jdk-7u79-linux-x64.tar.gz  安装路径为/usr/local/java
2 配置环境
```
vi /etc/profile
```
在最下面添加
```
export JAVA_HOME=/usr/local/java/jdk1.7.0_79
export JRE_HOME=/usr/local/java/jdk1.7.0_79/jre
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH
export PATH=$JAVA_HOME/bin:$PATH
```
保存后执行
```
source /etc/profile
```
3 安装amoeba  这里我下载的amoeba-mysql-3.0.4-BETA-distribution.zip unzip amoeba-mysql-3.0.4-BETA-distribution.zip
安装目录是
```
/usr/local/amoeba/amoeba-mysql-3.0.4-BETA
```
配置两个文件：conf/dbServers.xml和conf/amoeba.xml
amoeba.xml如下
```
<?xml version="1.0" encoding="gbk"?>

<!DOCTYPE amoeba:configuration SYSTEM "amoeba.dtd">
<amoeba:configuration xmlns:amoeba="http://amoeba.meidusa.com/">

        <proxy>

                <!-- service class must implements com.meidusa.amoeba.service.Service -->
                <service name="Amoeba for Mysql" class="com.meidusa.amoeba.mysql.server.MySQLService">
                        <!-- port -->
                        <property name="port">8066</property>

                        <!-- bind ipAddress -->

                        <property name="ipAddress">172.16.6.146</property>

                        <property name="connectionFactory">
                                <bean class="com.meidusa.amoeba.mysql.net.MysqlClientConnectionFactory">
                                        <property name="sendBufferSize">128</property>
@                                       
"amoeba.xml" 88L, 3019C
<?xml version="1.0" encoding="gbk"?>

<!DOCTYPE amoeba:configuration SYSTEM "amoeba.dtd">
<amoeba:configuration xmlns:amoeba="http://amoeba.meidusa.com/">

        <proxy>

                <!-- service class must implements com.meidusa.amoeba.service.Service -->
                <service name="Amoeba for Mysql" class="com.meidusa.amoeba.mysql.server.MySQLService">
                        <!-- port -->
                        <property name="port">8066</property>

                        <!-- bind ipAddress -->

                        <property name="ipAddress">172.16.6.146</property>

                        <property name="connectionFactory">
                                <bean class="com.meidusa.amoeba.mysql.net.MysqlClientConnectionFactory">
                                        <property name="sendBufferSize">128</property>
                                        <property name="receiveBufferSize">64</property>
                                </bean>
                        </property>

                        <property name="authenticateProvider">
                                <bean class="com.meidusa.amoeba.mysql.server.MysqlClientAuthenticator">

                                        <property name="user">root</property>

                                        <property name="password">111111</property>

                                        <property name="filter">
                                                <bean class="com.meidusa.toolkit.net.authenticate.server.IPAccessController">
                                                        <property name="ipFile">${amoeba.home}/conf/access_list.conf</property>
                                                </bean>
                                        </property>
                                </bean>
                        </property>

                </service>

                <runtime class="com.meidusa.amoeba.mysql.context.MysqlRuntimeContext">

                        <!-- proxy server client process thread size -->
                        <property name="executeThreadSize">128</property>

                        <!-- per connection cache prepared statement size  -->
                        <property name="statementCacheSize">500</property>

                        <!-- query timeout( default: 60 second , TimeUnit:second) -->
                        <property name="queryTimeout">60</property>
                </runtime>

        </proxy>

        <!--
                Each ConnectionManager will start as thread
                manager responsible for the Connection IO read , Death Detection
        -->
        <connectionManagerList>
                <connectionManager name="defaultManager" class="com.meidusa.toolkit.net.MultiConnectionManagerWrapper">
                        <property name="subManagerClassName">com.meidusa.toolkit.net.AuthingableConnectionManager</property>
                </connectionManager>
        </connectionManagerList>

                <!-- default using file loader -->
        <dbServerLoader class="com.meidusa.amoeba.context.DBServerConfigFileLoader">
                <property name="configFile">${amoeba.home}/conf/dbServers.xml</property>
        </dbServerLoader>

        <queryRouter class="com.meidusa.amoeba.mysql.parser.MysqlQueryRouter">
                <property name="ruleLoader">
                        <bean class="com.meidusa.amoeba.route.TableRuleFileLoader">
                                <property name="ruleFile">${amoeba.home}/conf/rule.xml</property>
                                <property name="functionFile">${amoeba.home}/conf/ruleFunctionMap.xml</property>
                        </bean>
                </property>
                <property name="sqlFunctionFile">${amoeba.home}/conf/functionMap.xml</property>
                <property name="LRUMapSize">1500</property>

                <property name="defaultPool">master1</property>

                <property name="writePool">master1</property> (写库)
                <property name="readPool">slave1</property>(读库)

                <property name="needParse">true</property>
        </queryRouter>
</amoeba:configuration>
```
下面是dbServers.xml的配置
```
<?xml version="1.0" encoding="gbk"?>

<!DOCTYPE amoeba:dbServers SYSTEM "dbserver.dtd">
<amoeba:dbServers xmlns:amoeba="http://amoeba.meidusa.com/">

                <!--
                        Each dbServer needs to be configured into a Pool,
                        If you need to configure multiple dbServer with load balancing that can be simplified by the following configuration:
                         add attribute with name virtual = "true" in dbServer, but the configuration does not allow the element with name factoryConfig
                         such as 'multiPool' dbServer
                -->

        <dbServer name="abstractServer" abstractive="true">
                <factoryConfig class="com.meidusa.amoeba.mysql.net.MysqlServerConnectionFactory">
                        <property name="connectionManager">${defaultManager}</property>
                        <property name="sendBufferSize">64</property>
                        <property name="receiveBufferSize">128</property>

                        <!-- mysql port -->
                        <property name="port">3306</property>(主从库允许的端口)

                        <!-- mysql schema -->
                        <property name="schema">db</property> (允许读写分离的数据库)

                        <!-- mysql user -->
                        <property name="user">shmily</property> (主从库分配给amoeba的账户)

                        <property name="password">shmily</property> (主从库分配给amoeba的密码)
                </factoryConfig>

                <poolConfig class="com.meidusa.toolkit.common.poolable.PoolableObjectPool">
                        <property name="maxActive">500</property>
                        <property name="maxIdle">500</property>
                        <property name="minIdle">1</property>
                        <property name="minEvictableIdleTimeMillis">600000</property>
                        <property name="timeBetweenEvictionRunsMillis">600000</property>
                        <property name="testOnBorrow">true</property>
                        <property name="testOnReturn">true</property>
                        <property name="testWhileIdle">true</property>
                </poolConfig>
        </dbServer>
          (写库的配置)
        <dbServer name="master1"  parent="abstractServer">
                <factoryConfig>
                        <!-- mysql ip -->
                        <property name="ipAddress">172.16.6.143</property>
                </factoryConfig>
        </dbServer>
          (读库的配置 ，可以配置多个)
        <dbServer name="slave1"  parent="abstractServer">
                <factoryConfig>
                        <!-- mysql ip -->
                        <property name="ipAddress">172.16.6.149</property>
                </factoryConfig>
        </dbServer>
（当为多个读库时，同时还得设置这里）
        <dbServer name="virtualbox" virtual="true">
                <poolConfig class="com.meidusa.amoeba.server.MultipleServerPool">
                        <!-- Load balancing strategy: 1=ROUNDROBIN , 2=WEIGHTBASED , 3=HA-->
                        <property name="loadbalance">1</property>

                        <!-- Separated by commas,such as: server1,server2,server1 -->
                        <property name="poolNames">slave1</property>
                </poolConfig>
        </dbServer>

</amoeba:dbServers>
```
以上则是配置文件

启动amoeba操作

切换到amoeba目录

cd /usr/local/moeba/moeba-mysql-3.0.4-BETA/bin

启动

./launcher

停止

./shutdown

从库远程登录调度服务器

mysql -uroot -p111111 -h172.16.6.146 -P8066

ps 查看进程
kill -9 pid 强制杀死进程

rpm ql 软件 查看软件路径

rpm -ivh rpm包   安装rpm包

rz windows复制文件

rpm -qa|grep XX 查看相关安装的软件

yum list| grep XX 列表

用户组列表文件：/etc/group
查看系统中有哪些用户：cut -d : -f 1 /etc/passwd查看可以登录系统的用户：cat /etc/passwd | grep -v /sbin/nologin | cut -d : -f 1查看用户操作：w命令(需要root权限)查看某一用户：w 用户名查看登录用户：who查看用户登录历史记录：last